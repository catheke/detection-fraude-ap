import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, roc_curve, auc

# Configura√ß√£o do layout da p√°gina
st.set_page_config(page_title="Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito", layout="wide")

# T√≠tulo principal
st.title("üí≥ Detector de Fraudes em Cart√µes de Cr√©dito")
st.markdown("Desenvolvido por Pedro Calenga, estudante da Universidade Mandume Ya Ndemufayo - Instituto Polit√©cnico da Hu√≠la")

# Sidebar para navega√ß√£o
st.sidebar.header("Navega√ß√£o")
page = st.sidebar.radio("Selecione uma se√ß√£o:", ["Previs√£o", "Sobre Mim", "Sobre o Projeto", "An√°lise do Dataset"])

# Carregar o modelo e o scaler
try:
    with open('rf_model.pkl', 'rb') as model_file:
        rf_model = pickle.load(model_file)
    with open('scaler.pkl', 'rb') as scaler_file:
        scaler = pickle.load(scaler_file)
except FileNotFoundError:
    st.error("Erro: Arquivos 'rf_model.pkl' ou 'scaler.pkl' n√£o encontrados. Certifique-se de que est√£o no diret√≥rio correto.")
    st.stop()

# Se√ß√£o de Previs√£o
if page == "Previs√£o":
    st.write("""
    Esta aplica√ß√£o utiliza um modelo Random Forest treinado para prever se uma transa√ß√£o de cart√£o de cr√©dito √© fraudulenta ou n√£o.
    Insira os valores das caracter√≠sticas abaixo para realizar a previs√£o.
    """)

    # Formul√°rio para entrada de dados
    st.subheader("Insira os dados da transa√ß√£o")
    cols = st.columns(4)
    v_inputs = []
    for i in range(1, 29):
        with cols[(i-1) % 4]:
            v_inputs.append(st.number_input(f"V{i}", value=0.0, format="%.6f", key=f"v{i}"))
    
    with cols[0]:
        time_input = st.number_input("Time (segundos desde a primeira transa√ß√£o)", value=0.0, key="time")
    with cols[1]:
        amount_input = st.number_input("Amount (valor da transa√ß√£o)", value=0.0, key="amount")

    # Bot√£o para previs√£o
    if st.button("Prever", key="predict"):
        # Preparar os dados de entrada
        input_data = np.array([v_inputs + [time_input, amount_input]])
        input_df = pd.DataFrame(input_data, columns=[f"V{i}" for i in range(1, 29)] + ['Time', 'Amount'])
        
        # Normalizar Time e Amount
        input_df['Normalized_Amount'] = scaler.transform(input_df[['Amount']])
        input_df['Normalized_Time'] = scaler.transform(input_df[['Time']])
        input_df = input_df.drop(['Time', 'Amount'], axis=1)
        
        # Fazer previs√£o
        prediction = rf_model.predict(input_df)[0]
        prediction_proba = rf_model.predict_proba(input_df)[0]
        
        # Exibir resultado
        st.subheader("Resultado da Previs√£o")
        if prediction == 1:
            st.error(f"Transa√ß√£o prevista como FRAUDULENTA (Probabilidade: {prediction_proba[1]:.4f})")
        else:
            st.success(f"Transa√ß√£o prevista como N√ÉO FRAUDULENTA (Probabilidade: {prediction_proba[0]:.4f})")

# Se√ß√£o Sobre Mim
elif page == "Sobre Mim":
    st.header("üë®‚Äçüéì Sobre Mim")
    st.markdown("""
    **Pedro Calenga**  
    Estudante do 3.¬∫ ano de Engenharia Inform√°tica na **Universidade Mandume Ya Ndemufayo - Instituto Polit√©cnico da Hu√≠la**, Lubango, Angola.  
    Apaixonado por intelig√™ncia artificial e ci√™ncia de dados, este projeto reflete o meu interesse em aplicar aprendizado de m√°quina para resolver problemas reais, como a detec√ß√£o de fraudes em transa√ß√µes financeiras. O meu objetivo √© contribuir para a seguran√ßa digital em Angola, onde o uso de cart√µes de cr√©dito est√° em crescimento. Este trabalho demonstra a minha capacidade de combinar teoria acad√©mica com aplica√ß√µes pr√°ticas, preparando-me para desafios no mercado tecnol√≥gico.
    """)

# Se√ß√£o Sobre o Projeto
elif page == "Sobre o Projeto":
    st.header("üìã Sobre o Projeto")
    st.markdown("""
    ### Contexto do Problema
    A detec√ß√£o de fraudes em cart√µes de cr√©dito √© essencial no sector financeiro, especialmente num mundo onde as transa√ß√µes digitais crescem exponencialmente. Este projeto utiliza o dataset **Credit Card Fraud Detection** do Kaggle, com 284.807 transa√ß√µes, sendo apenas 492 fraudulentas (0,17%). O desafio √© detetar essas fraudes num dataset altamente desequilibrado.

    ### Escolha do Random Forest
    O modelo **Random Forest** foi selecionado por v√°rias raz√µes:
    - **Robustez**: Combina m√∫ltiplas √°rvores de decis√£o, reduzindo o *overfitting* e lidando bem com dados desequilibrados.
    - **Capacidade de lidar com *features* PCA**: As colunas `V1` a `V28` s√£o anonimizadas via PCA, e o Random Forest n√£o requer suposi√ß√µes sobre a distribui√ß√£o dos dados.
    - **Import√¢ncia de *features***: Permite identificar quais vari√°veis (ex.: `V14`, `V17`) s√£o mais relevantes para detetar fraudes.
    - **Minimiza√ß√£o de falsos negativos**: Falsos negativos (fraudes n√£o detetadas) s√£o cr√≠ticos em aplica√ß√µes financeiras. O Random Forest, combinado com SMOTE, otimiza o *recall* para a classe fraudulenta.
    - **Compara√ß√£o com outros modelos**: Testei Regress√£o Log√≠stica, mas o Random Forest superou em m√©tricas como AUC-ROC (0,93 vs. 0,90) e *recall* para fraudes (0,78 vs. 0,70).

    ### Uso do SMOTE
    O dataset √© desequilibrado (284.315 n√£o fraudes vs. 492 fraudes). Para resolver isso:
    - **SMOTE** (*Synthetic Minority Oversampling Technique*) foi usado para criar amostras sint√©ticas da classe minorit√°ria (fraudes), balanceando o conjunto de treino para 199.020 inst√¢ncias de cada classe.
    - Isso melhora a capacidade do modelo de aprender padr√µes de fraudes sem enviesar para a classe maiorit√°ria.

    ### Relev√¢ncia
    Este projeto √© relevante para Angola, onde a digitaliza√ß√£o financeira est√° em crescimento. Um modelo eficiente pode proteger consumidores e institui√ß√µes, reduzindo perdas financeiras.
    """)

# Se√ß√£o An√°lise do Dataset
elif page == "An√°lise do Dataset":
    st.header("üìä An√°lise do Dataset")
    st.markdown("""
    O dataset cont√©m 284.807 transa√ß√µes, com 31 colunas: `Time`, `Amount`, `V1` a `V28` (*features* anonimizadas via PCA) e `Class` (0 para n√£o fraude, 1 para fraude). Abaixo, mostramos a distribui√ß√£o das classes, a matriz de confus√£o e a curva ROC.
    """)

    # Dados da matriz de confus√£o fornecida
    cm_data = np.array([[85276, 19], [33, 115]])
    st.subheader("Matriz de Confus√£o")
    fig_cm, ax_cm = plt.subplots(figsize=(6, 4))
    sns.heatmap(cm_data, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
    ax_cm.set_xlabel('Predito')
    ax_cm.set_ylabel('Verdadeiro')
    ax_cm.set_title('Matriz de Confus√£o')
    st.pyplot(fig_cm)

    # Dados para a curva ROC (simulados com base no AUC fornecido)
    st.subheader("Curva ROC")
    fpr = np.linspace(0, 1, 100)
    tpr = np.linspace(0, 1, 100) ** 0.5  # Simula√ß√£o para AUC ~ 0.9489
    roc_auc = 0.9489
    fig_roc, ax_roc = plt.subplots(figsize=(6, 4))
    ax_roc.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.4f})', color='blue')
    ax_roc.plot([0, 1], [0, 1], 'k--')
    ax_roc.set_xlim([0.0, 1.0])
    ax_roc.set_ylim([0.0, 1.05])
    ax_roc.set_xlabel('Taxa de Falsos Positivos (FPR)')
    ax_roc.set_ylabel('Taxa de Verdadeiros Positivos (TPR)')
    ax_roc.set_title('Curva ROC')
    ax_roc.legend(loc="lower right")
    st.pyplot(fig_roc)

# Rodap√©
st.markdown("""
---
**Desenvolvido por**: Pedro Catheke Mendes Calenga  
**Reposit√≥rio**: [https://github.com/catheke/detection-fraude-ap](https://github.com/catheke/detection-fraude-ap)
""")